{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차 개념정리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeeDW5ScORZiNv0qOFVn8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyo9381/AI---study/blob/master/like%20lion/pre%20course/3%EC%A3%BC%EC%B0%A8_%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOX2HoPfxIDf",
        "colab_type": "text"
      },
      "source": [
        "파이썬에서 제이슨 사용하는 방법\n",
        "```\n",
        "import json\n",
        "with open('student_file.json') as json file:\n",
        "  json_data = json.load(json_file)\n",
        "\n",
        "json_data\n",
        "```\n",
        "\n",
        "* json형식의 데이터를 열어 파이썬 객체로 읽어와 주는것\n",
        "\n",
        "\n",
        "파이썬 객체를 제이슨 스타일로 바꾸는 방법\n",
        "```\n",
        "st_json = json.dumps(student_data)\n",
        "st_json\n",
        "```\n",
        "json.dumps(student_data, indent=4)\n",
        "json.dumps(student_data, indent=4,sort_keys = True)\n",
        "\n",
        "\n",
        "open api : 인터넷 이용자가 웹검색 결과 및 사용자 인터페이스 등을 수동적으로 제공받는데 그치지 않고 직접 응용 프로그램과 서비스를 개발할 수 있도록 공개된 api\n",
        "\n",
        "오픈api를 사용하기 위해서는 key를 사용할수있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyejfrj411Ki",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝을 위한 기초 수학 \n",
        "\n",
        "\n",
        "과거의 관측을 기반으로 새롱룬 샘플의값을 예측하는것 \n",
        "\n",
        "목적함수 : 목적함숫값이 가장 작은것을 찾는것이 우리의 목표\n",
        "\n",
        "\n",
        "경사 하강법 :  목적함수의값을 최소화 시키기 위해 마치 경사를 내려가듯 최소값을 찾는 기법 \n",
        "\n",
        "학습률의 값을 너무 크게 잡으면 발산이 일어나고 \n",
        "너무 작게 잡으면 수렴속도 지연이 된다. \n",
        "\n",
        "\n",
        "\n",
        "* 목적함수가 다변수 함수 모양으로 나온다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5urlgyHdMP3",
        "colab_type": "text"
      },
      "source": [
        "## 분류 문제 [1]\n",
        "\n",
        "하나의 문제를 해결하기 위해 여러 학습알고리즘 비교해야한다.\n",
        "  - 변수의 특성\n",
        "  - 데이터의 개수\n",
        "  - 노이즈 데이터의 양\n",
        "  - 클래스의 선형적 구분여부\n",
        "\n",
        "로지스틱 회귀 : 분류를 확률로 생각하는 방식\n",
        "\n",
        "어느 클래스에 분류되는지 구하는것 << 함수가 필요\n",
        "\n",
        "이것을 시그모리드 함수라고 한다.\n",
        "\n",
        "\n",
        "f(x) =  1/ 1+e^(-z)\n",
        "z = W^Tx\n",
        "\n",
        "서포트 백터머신 (SVM)\n",
        "목적 :  마진을 최대화 하는것\n",
        "초평면(결정경계)\n",
        "\n",
        "svm의 단점은 계산비용이 많이 발생한다. 그리고 컴퓨팅 파워가 많이 든다.\n",
        "이를해결하기\n",
        "\n",
        "## 분류 문제 [2]\n",
        "\n",
        "* 결정 트리 학습 : Q&A같은 느낌의 알고리즘이다.\n",
        "\n",
        "목적함수의 목적 : 가장 정보가 풍부한 특성으로 노트를 나누기 위함 , 트리 알고리즘으로 최적화 \n",
        "\n",
        "각 분할에서 정보이득을 최대화 해야하는 임무르 ㄹ가지고 있다. \n",
        "\n",
        "(엔트로피)\n",
        "\n",
        " 한노드의 모든 데이터가 같은 클래스라면 엔트로피는 0\n",
        " 반대로 클래스 분포가 균등함다면 엔트로피는 최대 1\n",
        " 트리의 상호의존 정보를 최대화 하는것\n",
        "\n",
        "(지니 불순도)\n",
        "\n",
        "클래스가 완벽하게 섞여있을때 최대값이다.\n",
        "\n",
        "(분류오차)\n",
        "\n",
        "두 클래스가 같은 비율일때 최대값 0.5을 나타낸다 \n",
        "하지만 권장하지는 않는다. \n",
        "\n",
        "\n",
        "* KNN \n",
        "\n",
        "과적합과 과소적합 사이의 k 를 발견하는것이 중요하다.\n",
        "\n",
        "차원의저주 : \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAMuXVSqoQoM",
        "colab_type": "text"
      },
      "source": [
        "## 머신러닝 군집문제 [1]\n",
        "\n",
        "비지도 학습 군집분석\n",
        "\n",
        "정답을 모르는 데이터 안에서 숨겨진 데이터를 찾는것 = 군집\n",
        "\n",
        "(k-평균) \n",
        "프로토타입 군집\n",
        "\n",
        "연속적인 특성에서는 비슷한 데이터 포인트의 센트로이드 \n",
        "\n",
        "범주현 특성에서는 메도이드 (medoid- 가장 자주 등장하는 포인트)\n",
        "\n",
        "k-평균 4단계 알고리즘\n",
        "- 데이터 포인트에서 랜덤하게 k개의 센트로이드를 초기 클러스터 중심으로 선택\n",
        "- 각 데이터를 가장 가까운 센트로이드에 할당합니다.\n",
        "- 할당된 샘플들의 중심으로 센트로이드를 이동시키니다.\n",
        "- 클러스터 할당이 변하지 않거나, 사용자가 지정한 허용오차나, 최대 반복횟수에 도달할 때 까지 두번째와 세번째 과정을 반복합니다.\n",
        "\n",
        "클러스터내의 제곱 오차합(SSE)을 반복적으로 최소화\n",
        "변화량에 대한 허용 오차값이 일정수준내로 들어온다면 최적화가 완료 되는것이다. \n",
        "\n",
        "사이킷런 \n",
        "엘보우방법 : SSE의 값이 최소가 되도록 클러스터의 중심을 결정해나가는 방법, 클러스터의 개수를 1로 두고 SSE계산 클러스터 개수를 2로두고 SSE계산이다. \n",
        "\n",
        "실루엣그래프 : 클러스터 내 데이터들이 얼마나 조밀하게 모여있는지를 측정하는 그래프 도구 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VuxCUOtw9Za",
        "colab_type": "text"
      },
      "source": [
        "## 머신러닝 군집문제[2]\n",
        "\n",
        "### 계층군집\n",
        "\n",
        "병합계층군집 \n",
        "\n",
        "분할 계층 군집 \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}